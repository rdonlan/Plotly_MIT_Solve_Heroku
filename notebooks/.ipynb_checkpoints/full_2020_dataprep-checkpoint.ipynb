{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from utils import zebra\n",
    "import re\n",
    "solver_data = pd.read_excel(\"2020_Partner_Solver_original.xlsx\", sheet_name='Solver Data')\n",
    "partner_data =  pd.read_excel(\"2020_Partner_Solver_original.xlsx\", sheet_name='Partner Data')\n",
    "solver_data = solver_data.rename(columns={'Solution Name': 'Org'})\n",
    "partner_data = partner_data.rename(columns={'Organization Name': 'Org',\n",
    "                                            'Challenge':'Challenge Preference',\n",
    "                                            'Stage': 'Solution Preference: Organization Stage',\n",
    "                                            'Expertise': 'Partnership Preference: Non-Financial',\n",
    "                                           'Geography': 'Geo Interests'})\n",
    "\n",
    "partner_data = partner_data.replace(np.nan, \"Noval\")\n",
    "solver_data  = solver_data.replace(np.nan, \"Noval\")\n",
    "solver_data_copy = solver_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def split_collect(df_cols, delimiter=','):\n",
    "    \"\"\"\n",
    "        Split each value in a cell based on a delimiter \n",
    "        and return a list of unique options \n",
    "        \n",
    "    \"\"\"\n",
    "    opts = df_cols.apply(lambda x :  x.split(delimiter)   ).to_list()\n",
    "    flatten_opts = [x.strip() for y in opts for x in y ]\n",
    "    opts = pd.DataFrame(data=flatten_opts, columns=['options'])\n",
    "    opts = opts['options'].value_counts().index.to_list()\n",
    "    return opts\n",
    "\n",
    "\n",
    "def expand_col(df_col, delimiter=',',col_name='new_col'): \n",
    "    \"\"\"\n",
    "    Take in a pandas series whose elements are\n",
    "    a string. Split each cell of the series with\n",
    "    a delimiter which is used togenerate an N column dataframe. \n",
    "    N is the longest list amongst the cells of df_col after\n",
    "    they have been split\n",
    "    \n",
    "    \"\"\"\n",
    "#     df_col = df_col.apply(lambda x : x.str.split(delimiter)).to_list()\n",
    "    df_col = df_col.str.split(delimiter).to_list()\n",
    "    new_df = pd.DataFrame(data=df_col)\n",
    "    ncols = len(new_df.columns)\n",
    "    new_names = []\n",
    "    for x in range(1, ncols+1): \n",
    "        new_name =\"\".join((col_name,'_', str(x)))\n",
    "        new_df = new_df.rename(columns={x-1:new_name})\n",
    "    return new_df\n",
    "\n",
    "\n",
    "def match_single_to_multi(single_df, multi_df, single_match_on='None'): \n",
    "    \"\"\"\n",
    "    Generate a pivot table between a df which has a single of choices \n",
    "    and a df with multiple columns of choices\n",
    "    \n",
    "    \"\"\"\n",
    "    melted_df = pd.melt(multi_df,id_vars='Org')\n",
    "    melted_df = melted_df.drop(columns='variable')\n",
    "    melted_df = melted_df.apply(lambda x: x.str.strip() if x.dtype == \"object\" else x)\n",
    "    single_df = single_df.apply(lambda x: x.str.strip() if x.dtype == \"object\" else x)\n",
    "    matched_df = pd.merge(melted_df, single_df, how='outer', left_on='value', right_on=single_match_on)\n",
    "    matched_df = matched_df.replace(np.nan, 'Noval')\n",
    "    matched_df['value'] = matched_df['value'].apply(lambda x : 0 if x == None else 1)\n",
    "    pivot_table = pd.pivot_table(matched_df, index='Org_x', columns=['Org_y'], values='value', dropna=False,  aggfunc=np.sum)\n",
    "\n",
    "    return pivot_table\n",
    "\n",
    "\n",
    "def match_multi(df1, df2):\n",
    "    \"\"\"\n",
    "    Match a feature with multiple options to another option with multiple options\n",
    "    \"\"\"\n",
    "    \n",
    "    melted_df1 = pd.melt(df1,id_vars='Org').fillna('Noval')\n",
    "    melted_df2 = pd.melt(df2, id_vars='Org').fillna('Noval')\n",
    "    melted_df1 = melted_df1.drop(columns='variable')\n",
    "    melted_df2 = melted_df2.drop(columns='variable')\n",
    "    melted_df1 = melted_df1.apply(lambda x: x.str.strip() if x.dtype == \"object\" else x)\n",
    "    melted_df2 = melted_df2.apply(lambda x: x.str.strip() if x.dtype == \"object\" else x)\n",
    "    matched_df = pd.merge(melted_df1, melted_df2, how='outer', left_on='value', right_on='value')\n",
    "    matched_df = matched_df.replace(np.nan, 'Noval')\n",
    "    matched_df['value'] = matched_df['value'].apply(lambda x : 0 if  x == 'Noval' else 1)\n",
    "    pivot_table = pd.pivot_table(matched_df, index='Org_x', columns=['Org_y'], values='value',aggfunc=np.sum)\n",
    "    return pivot_table\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge column cleaning and matching\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "partner_challenge  = partner_data['Challenge Preference']\n",
    "partner_data['Challenge Preference'] = partner_data['Challenge Preference'].apply(lambda x: x.strip().replace(';',',') if ';' in x else x.strip() )\n",
    "partner_challenge_cols = expand_col(partner_data['Challenge Preference'], col_name ='Challenge')\n",
    "partner_challenge_opts = split_collect(partner_data['Challenge Preference'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "solver_challenge_opts = split_collect(solver_data['Challenge'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(solver_challenge_opts).issubset(set(partner_challenge_opts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above shows that all options in solvers are a subset of patners so no work required in correction! Next up is getting the matching sheet\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add challenge columns to partner data sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "partner_data_updated = partner_data.copy()\n",
    "partner_data_updated = partner_data_updated.drop(columns='Challenge Preference')\n",
    "partner_data_updated = pd.concat([partner_data_updated, partner_challenge_cols], axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Geo Interests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['North America',\n",
       " 'East Asia and Pacific',\n",
       " 'Sub-Saharan Africa',\n",
       " 'Europe and Central Asia',\n",
       " 'Latin America and the Caribbean',\n",
       " 'Middle East and North Africa',\n",
       " 'South Asia',\n",
       " 'Oceania',\n",
       " 'Noval']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "partner_data_updated['Geo Interest'] = partner_data_updated['Geo Interest'].apply(lambda x: x.strip().replace(';',',') if ';' in x else x.strip() )\n",
    "partner_geo_opts = split_collect(partner_data_updated['Geo Interest'])\n",
    "partner_geo_opts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Noval',\n",
       " 'North America',\n",
       " 'Sub-Saharan Africa',\n",
       " 'South Asia',\n",
       " 'Latin America and the Caribbean',\n",
       " 'Middle East and North Africa',\n",
       " 'East Asia and Pacific',\n",
       " 'Europe and Central Asia']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "solver_geo_opts = solver_data[['Geo 1', 'Geo 2', 'Geo 3']].apply(lambda x : \",\".join(x)   ,axis=1)\n",
    "solver_geo_opts = split_collect(solver_geo_opts)\n",
    "solver_geo_opts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(solver_geo_opts).issubset(set(partner_geo_opts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add geo columns to partner datasheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "partner_geo_cols = partner_data_updated['Geo Interest']\n",
    "\n",
    "partner_geo_cols = expand_col(partner_geo_cols, col_name='geo')\n",
    "\n",
    "# remove partner geo column and add individual geo columns\n",
    "partner_data_updated = pd.concat([partner_data_updated, partner_geo_cols], axis=1)\n",
    "partner_data_updated = partner_data_updated.drop(columns=['Geo Interest'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key needs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Noval',\n",
       " 'Business model (e.g. product-market fit, strategy & development)',\n",
       " 'Product / Service Distribution (e.g. expanding client base)',\n",
       " 'Monitoring & Evaluation (e.g. collecting/using data, measuring impact)',\n",
       " 'Human Capital (e.g. sourcing talent, board development, etc.)',\n",
       " 'Financial (e.g. improving accounting practices, pitching to investors)',\n",
       " 'Technology (e.g. software or hardware, web development/design, data analysis, etc.)',\n",
       " 'Public Relations (e.g. branding/marketing strategy, social and global media)',\n",
       " 'Other (explain below)',\n",
       " 'Legal or Regulatory Matters']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Partnership preferences non financal from partner data\n",
    "\n",
    "pref_name = 'Partnership Preference'\n",
    "prefs_columns = [x  for x in partner_data_updated.columns if pref_name in x]\n",
    "partner_prefs_opts = partner_data_updated[prefs_columns]\n",
    "partner_prefs_opts = split_collect(partner_prefs_opts.apply(lambda x : \";\".join(x)   ,axis=1), delimiter=';')\n",
    "partner_prefs_opts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Noval',\n",
       " 'Public Relations (e.g. branding/marketing strategy, social and global media)',\n",
       " 'Financial (e.g. improving accounting practices, pitching to investors)',\n",
       " 'Business model (e.g. product-market fit, strategy & development)',\n",
       " 'Human Capital (e.g. sourcing talent, board development, etc.)',\n",
       " 'Product / Service Distribution (e.g. expanding client base)',\n",
       " 'Technology (e.g. software or hardware, web development/design, data analysis, etc.)',\n",
       " 'Legal or Regulatory Matters',\n",
       " 'Other',\n",
       " 'Monitoring & Evaluation (e.g. collecting/using data, measuring impact)',\n",
       " 'Human Capital (i.e. sourcing talent, board development, etc.)']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "needs_name = 'Key Need'\n",
    "needs_columns = [x  for x in solver_data.columns if needs_name in x]\n",
    "solver_needs_opts = solver_data[needs_columns]\n",
    "solver_needs_opts = split_collect(solver_needs_opts.apply(lambda x : \";\".join(x)   ,axis=1), delimiter=';')\n",
    "solver_needs_opts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Human Capital (i.e. sourcing talent, board development, etc.)', 'Other'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if all the solver need options are in partner preferences\n",
    "set(solver_needs_opts).difference(set(partner_prefs_opts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Other (explain below)'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the opposite of the above\n",
    "set(partner_prefs_opts).difference(set(solver_needs_opts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correcting Human Captial in partner data\n",
    "wrong_str1 = 'Human Capital (e.g. sourcing talent, board development, etc.)'\n",
    "wrong_str2 = 'Other (explain below)'\n",
    "correct_str1 = 'Other'\n",
    "correct_str2 = 'Human Capital (i.e. sourcing talent, board development, etc.)'\n",
    "for pref in prefs_columns:\n",
    "    partner_data_updated[pref] = partner_data_updated[pref].apply(lambda x: x.replace(wrong_str1, correct_str1) if x == wrong_str1 else x )\n",
    "    partner_data_updated[pref] = partner_data_updated[pref].apply(lambda x: x.replace(wrong_str2, correct_str2) if x == wrong_str2 else x)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correcting Capital in solver data\n",
    "wrong_str1 = 'Human Capital (e.g. sourcing talent, board development, etc.)'\n",
    "correct_str2 = 'Human Capital (i.e. sourcing talent, board development, etc.)'\n",
    "solver_data_updated = solver_data.copy()\n",
    "for pref in needs_columns:\n",
    "    solver_data_updated[pref] = solver_data_updated[pref].apply(lambda x: x.replace(wrong_str1, correct_str1) if x == wrong_str1 else x )\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Noval',\n",
       " 'Other',\n",
       " 'Public Relations (e.g. branding/marketing strategy, social and global media)',\n",
       " 'Financial (e.g. improving accounting practices, pitching to investors)',\n",
       " 'Business model (e.g. product-market fit, strategy & development)',\n",
       " 'Product / Service Distribution (e.g. expanding client base)',\n",
       " 'Technology (e.g. software or hardware, web development/design, data analysis, etc.)',\n",
       " 'Legal or Regulatory Matters',\n",
       " 'Monitoring & Evaluation (e.g. collecting/using data, measuring impact)',\n",
       " 'Human Capital (i.e. sourcing talent, board development, etc.)']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Showing the partnership options after correcting for human capital\n",
    "needs_columns = [x  for x in solver_data_updated.columns if needs_name in x]\n",
    "solver_needs_opts = solver_data_updated[needs_columns]\n",
    "solver_needs_opts = split_collect(solver_needs_opts.apply(lambda x : \";\".join(x)   ,axis=1), delimiter=';')\n",
    "solver_needs_opts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage Match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "partner_data_updated['Solution Preference: Organization Stage'] = partner_data_updated['Solution Preference: Organization Stage'].apply(lambda x : x.replace(';',',' if ';' in x else x))\n",
    "partner_stage = partner_data_updated['Solution Preference: Organization Stage']\n",
    "partner_stage_opts = split_collect(partner_stage)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "solver_stage_opts = split_collect(solver_data_updated['Stage'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(solver_stage_opts).difference(set(partner_stage_opts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No difference! means all the options are the same! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add seprated stage columns to partner data sheet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "partner_stage_cols = expand_col(partner_stage, col_name='Stage')\n",
    "partner_data_updated = pd.concat([partner_data_updated, partner_stage_cols], axis=1)\n",
    "partner_data_updated = partner_data_updated.drop(columns=['Solution Preference: Organization Stage'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tech Match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Imaging and Sensor Technology', 'Virtual Reality / Augmented Reality'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "partner_tech_opts = split_collect(partner_data_updated['Technology Expertise'])\n",
    "tech_name = 'Tech'\n",
    "tech_cols = [x for x in solver_data_updated.columns if  tech_name in x]\n",
    "tech_cols.append('Org')\n",
    "solver_tech_cols = solver_data_updated[tech_cols]\n",
    "solver_tech_opts = split_collect(solver_tech_cols.apply(lambda x : \",\".join(x), axis=1))\n",
    "set(partner_tech_opts).difference(solver_tech_opts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "partner_tech_cols = expand_col(partner_data_updated['Technology Expertise'], col_name='tech')\n",
    "partner_data_updated = pd.concat([partner_data_updated, partner_tech_cols], axis=1)\n",
    "partner_data_updated = partner_data_updated.drop(columns=['Technology Expertise'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All matching sheets calculated here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Challenge Matching sheet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'Organization ID', 'Org', 'First Name', 'Last Name',\n",
       "       'Type', 'Funding Preference 1', 'Funding Preference 2',\n",
       "       'Funding Preference 3', 'Funding Preference 4',\n",
       "       'Partnership Preference: Non-Financial 1',\n",
       "       'Partnership Preference: Non-Financial 2',\n",
       "       'Partnership Preference: Non-Financial 3',\n",
       "       'Partnership Preference: Non-Financial 4',\n",
       "       'Partnership Preference: Non-Financial 5',\n",
       "       'Partnership Preference: Non-Financial 6',\n",
       "       'Partnership Preference: Non-Financial 7', 'Challenge_1', 'Challenge_2',\n",
       "       'Challenge_3', 'Challenge_4', 'Challenge_5', 'Challenge_6',\n",
       "       'Challenge_7', 'Challenge_8', 'Challenge_9', 'Challenge_10',\n",
       "       'Challenge_11', 'Challenge_12', 'Challenge_13', 'Challenge_14', 'geo_1',\n",
       "       'geo_2', 'geo_3', 'geo_4', 'geo_5', 'geo_6', 'geo_7', 'geo_8',\n",
       "       'Stage_1', 'Stage_2', 'Stage_3', 'Stage_4', 'Stage_5', 'tech_1',\n",
       "       'tech_2', 'tech_3', 'tech_4', 'tech_5', 'tech_6', 'tech_7', 'tech_8',\n",
       "       'tech_9'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "partner_data_updated = partner_data_updated.replace('None', 'Noval' ,regex=True)\n",
    "solver_data_updated = solver_data_updated.replace('None', 'Noval', regex=True)\n",
    "partner_data_updated = partner_data_updated.replace(np.nan, \"Noval\")\n",
    "solver_data_updated  = solver_data_updated.replace(np.nan, \"Noval\")\n",
    "partner_data_updated.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "chname = 'Challenge'\n",
    "challenge_cols = [x for x in partner_data_updated.columns if chname in x ]\n",
    "partner_challenge_cols = partner_data_updated[challenge_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pawan/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(78, 43)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "solver_challenge_cols = solver_data_updated[['Org', 'Challenge']]\n",
    "partner_challenge_cols['Org'] = partner_data_updated['Org']\n",
    "challenge_match = match_single_to_multi(solver_challenge_cols, partner_challenge_cols, single_match_on='Challenge')\n",
    "\n",
    "if 'Noval' in challenge_match.columns: \n",
    "    challenge_match = challenge_match.drop(columns=['Noval'])\n",
    "challenge_match.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening up single to multi function \n",
    "\n",
    "# single_df = solver_challenge_cols\n",
    "# multi_df = partner_challenge_cols\n",
    "# single_match_on = 'Challenge'\n",
    "\n",
    "# melted_df = pd.melt(multi_df,id_vars='Org')\n",
    "# melted_df = melted_df.drop(columns='variable')\n",
    "# melted_df = melted_df.apply(lambda x: x.str.strip() if x.dtype == \"object\" else x)\n",
    "# single_df = single_df.apply(lambda x: x.str.strip() if x.dtype == \"object\" else x)\n",
    "# matched_df = pd.merge(melted_df, single_df, how='outer', left_on='value', right_on=single_match_on)\n",
    "# matched_df = matched_df.replace(np.nan, 'Noval')\n",
    "# matched_df['value'] = matched_df['value'].apply(lambda x : 0 if x == None else 1)\n",
    "# pivot_table = pd.pivot_table(matched_df, index='Org_x', columns=['Org_y'], values='value', dropna=False,  aggfunc=np.sum)\n",
    "# pivot_table.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trouble shooting no match "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unshared_challenges_partners = set(partner_challenge_cols['Org'].to_list()).difference(set(pivot_table.index.to_list()))\n",
    "# challenges_missing = set(partner_challenge_opts).difference(set(solver_challenge_opts))\n",
    "# missing_indx = partner_challenge_cols[partner_challenge_cols.isin(challenges_missing)].any(1).to_numpy().nonzero()\n",
    "# possible_missing = partner_challenge_cols['Org'].loc[missing_indx].to_list()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This basically means that there are only 35 rows have matches, otherwise no matches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Geo Matching sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(78, 43)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "geo_cols = [x for x in partner_data_updated.columns if 'geo' in x]\n",
    "geo_cols.append('Org')\n",
    "partner_geo_cols = partner_data_updated[geo_cols]\n",
    "\n",
    "solver_geo_cols = solver_data_updated[['Org', 'Geo 1', 'Geo 2', 'Geo 3']]\n",
    "geo_match = match_multi(partner_geo_cols,solver_geo_cols)\n",
    "if 'Noval' in geo_match.columns: \n",
    "    geo_match = geo_match.drop(columns=['Noval'])\n",
    "geo_match.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Needs Matching sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(78, 43)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "needs_name ='Key Need'\n",
    "pref_name = 'Partnership Preference'\n",
    "prefs_columns = [x  for x in partner_data_updated.columns if pref_name in x]\n",
    "needs_columns = [x  for x in solver_data_updated.columns if needs_name in x]\n",
    "prefs_columns.append('Org')\n",
    "needs_columns.append('Org')\n",
    "partner_prefs_cols = partner_data_updated[prefs_columns]\n",
    "solver_needs_cols = solver_data_updated[needs_columns]\n",
    "needs_match = match_multi(partner_prefs_cols, solver_needs_cols)\n",
    "if 'Noval' in needs_match.columns: \n",
    "    needs_match = needs_match.drop(columns=['Noval'])\n",
    "needs_match.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage Matching sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(78, 43)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stage_name = 'Stage'\n",
    "stage_columns = [x  for x in partner_data_updated.columns if stage_name in x]\n",
    "stage_columns.append('Org')\n",
    "partner_stage_cols = partner_data_updated[stage_columns]\n",
    "solver_stage_cols = solver_data_updated[['Stage', 'Org']]\n",
    "stage_match = match_single_to_multi(solver_stage_cols, partner_stage_cols, single_match_on='Stage')\n",
    "\n",
    "if 'Noval' in stage_match.columns: \n",
    "    stage_match = stage_match.drop(columns=['Noval'])\n",
    "stage_match.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(stage_match.columns.to_list()).difference(set(needs_match.columns.to_list()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tech Matching Sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "tech_name = 'tech'\n",
    "tech_cols = [x for x in partner_data_updated.columns if  tech_name in x]\n",
    "tech_cols.append('Org')\n",
    "partner_tech_cols = partner_data_updated[tech_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pawan/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(78, 43)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "partner_tech_cols['Org'] = partner_data_updated['Org']\n",
    "tech_match = match_multi(partner_tech_cols, solver_tech_cols)\n",
    "if 'Noval' in tech_match.columns:\n",
    "    tech_match = tech_match.drop(columns=['Noval'])\n",
    "if 'Noval' in tech_match.index:\n",
    "    tech_match = tech_match.drop(index='Noval', axis=0) \n",
    "tech_match.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summing all sheets \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['SmartFish Mexico', 'Universally Friendly Obturator', 'The Last Mile',\n",
       "       'Thaki', 'Humans inthe Loop', 'Beewise', 'AHSA Platform',\n",
       "       'Empower 1.5M Girls to go to School', 'Amplify Her Voice',\n",
       "       'Sisters of Code', 'Democratizing Ultrasound Africa',\n",
       "       'Jute-based biodegradable PPE', 'InsectiPro',\n",
       "       'Mosquito-borne disease prevention', 'SOLshare', 'PENSA *660#', 'D2',\n",
       "       'Ubenwa', 'Whole Surplus', 'Symbrosia', 'Maziwa Breast Pump',\n",
       "       'TamoJunto.org.br', 'MapSights', 'PODD', 'Salamat',\n",
       "       'Biometricsfor vaccine delivery', 'Bioforge Neonatal Incubator',\n",
       "       'eggXYt', 'Bambara Milk', 'Someone Somewhere', 'Maisha',\n",
       "       'Asia Initiatives Learning Cascades', 'Yiya AirScience', 'Nucleus',\n",
       "       'Girls-4-Girls'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tech_matched = tech_matched.fillna(0)\n",
    "# needs_match = needs_match.fillna(0)\n",
    "# geo_match = geo_match.fillna(0)\n",
    "# stage_match= stage_match.fillna(0)\n",
    "# challenge_match = challenge_match.fillna(0)\n",
    "\n",
    "partner_solver_weights = pd.read_excel('input_data/2020_input_data.xlsx', sheet_name= 'Partner Solver Weights')\n",
    "geo_weights_pivot = pd.pivot(partner_solver_weights[['Org_y', 'Org_x', 'geo_weights']], columns='Org_x', index='Org_y' )\n",
    "needs_weights_pivot = pd.pivot(partner_solver_weights[['Org_y', 'Org_x', 'needs_weights']], columns='Org_x', index='Org_y' )\n",
    "challenge_weights_pivot = pd.pivot(partner_solver_weights[['Org_y', 'Org_x', 'challenge_weights']], columns='Org_x', index='Org_y' )\n",
    "stage_weights_pivot = pd.pivot(partner_solver_weights[['Org_y', 'Org_x', 'stage_weights']], columns='Org_x', index='Org_y' )\n",
    "\n",
    "# challenge_term = 10*pd.DataFrame(challenge_weights_pivot.values*challenge_match.astype(float).values, columns=challenge_weights_pivot.columns, index=challenge_weights_pivot.index)['challenge_weights']\n",
    "# stage_term = pd.DataFrame(stage_weights_pivot.values*stage_match.astype(float).values, columns=stage_weights_pivot.columns, index=stage_weights_pivot.index)\n",
    "# geo_term = pd.DataFrame(geo_weights_pivot.values*geo_match.astype(float).values, columns=geo_weights_pivot.columns, index=geo_weights_pivot.index)['geo_weights']\n",
    "# geo_stage_term = 100*pd.DataFrame(geo_term.values*stage_term.values, columns=stage_term.columns, index=stage_term.index)['stage_weights']\n",
    "# needs_term =  pd.DataFrame(needs_weights_pivot.values*needs_matched.astype(float).values, columns=needs_weights_pivot.columns, index=needs_weights_pivot.index)['needs_weights']\n",
    "\n",
    "# total_score = challenge_term  + geo_stage_term + needs_term\n",
    "partner_solver_weights['Org_x'].value_counts().index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "partner_data_updated = partner_data_updated.replace('None', 'Noval' ,regex=True)\n",
    "solver_data_updated = solver_data_updated.replace('None', 'Noval', regex=True)\n",
    "partner_data_updated = partner_data_updated.replace(np.nan, \"Noval\")\n",
    "solver_data_updated  = solver_data_updated.replace(np.nan, \"Noval\")\n",
    "\n",
    "file_name = '2020_data.xlsx'\n",
    "with pd.ExcelWriter(file_name) as writer: \n",
    "    partner_data_updated.to_excel(writer, sheet_name='Partner Data', index=False)\n",
    "    solver_data_updated.to_excel(writer, sheet_name='Solver Team Data', index= False)\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pawan/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "partners_df = partner_data_updated.copy()\n",
    "solvers_df = solver_data_updated.copy()\n",
    "\n",
    "ch_partners = partners_df[[\"Org\", 'Challenge_1']]\n",
    "ch_solver = solvers_df[[\"Org\",\"Challenge\"]]\n",
    "ch_solver['Challange'] = ch_solver['Challenge'].apply(lambda x: x.strip() )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a cleaned verison the challenges table from partners\n",
    "ch_partners_challenges = ch_partners.copy()\n",
    "\n",
    "\n",
    "# Merge partners and solvers challenge needs\n",
    "merged_df = pd.merge(ch_solver,\n",
    "                         ch_partners_challenges,\n",
    "                         left_on=\"Challenge\",\n",
    "                         right_on='Challenge_1',\n",
    "                         how='outer')\n",
    "merged_df = merged_df.replace(np.nan, 'Noval')\n",
    "# Generate a pivot table on partners and solvers using the merged dataset                          \n",
    "merged_pivot_table = pd.pivot_table(merged_df,\n",
    "                                        values=\"Challenge\",\n",
    "                                        index=[\"Org_y\"],\n",
    "                                        columns=[\"Org_x\"],\n",
    "                                        aggfunc=np.sum)\n",
    "\n",
    "merged_pivot_table\n",
    "if 'Noval' in merged_pivot_table.columns:\n",
    "    merged_pivot_table = merged_pivot_table.drop(columns=['Noval'])\n",
    "if 'Noval' in merged_pivot_table.index:\n",
    "    merged_pivot_table = merged_pivot_table.drop(index='Noval', axis=0) \n",
    "\n",
    "# Set all the values on the pivot table to 1 and reset index  \n",
    "challenges_pivot = merged_pivot_table.copy()\n",
    "challenges_pivot[:] = 1\n",
    "challenges_pivot_unpivoted = challenges_pivot.reset_index()\n",
    "\n",
    "# Unpivot the pivot table acquire a list containing partner and solver matches\n",
    "unpivoted_inital_table = pd.melt(challenges_pivot_unpivoted, id_vars=\"Org_y\")\n",
    "zero_column = unpivoted_inital_table['value']\n",
    "\n",
    "# Assign new columns that contain inital scores for each key needs\n",
    "unpivoted_inital_table = unpivoted_inital_table.assign(geo_weights=zero_column, \n",
    "                        challenge_weights=zero_column,\n",
    "                        needs_weights=zero_column, \n",
    "                        stage_weights=zero_column)\n",
    "\n",
    "# Drop the value column since it we only care about the 4 needs created above                        \n",
    "partners_solvers_weights =  unpivoted_inital_table.drop(columns='value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3354"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1225"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "35*35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
