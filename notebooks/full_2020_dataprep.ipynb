{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from utils import zebra\n",
    "import re\n",
    "solver_data = pd.read_excel(\"2020_Partner_Solver_original.xlsx\", sheet_name='Solver Data')\n",
    "partner_data =  pd.read_excel(\"2020_Partner_Solver_original.xlsx\", sheet_name='Partner Data')\n",
    "solver_data = solver_data.rename(columns={'Solution Name': 'Org'})\n",
    "partner_data = partner_data.rename(columns={'Organization Name': 'Org',\n",
    "                                            'Challenge':'Challenge Preference',\n",
    "                                            'Stage': 'Solution Preference: Organization Stage',\n",
    "                                            'Expertise': 'Partnership Preference: Non-Financial',\n",
    "                                           'Geography': 'Geo Interests'})\n",
    "\n",
    "partner_data = partner_data.replace(np.nan, \"Noval\")\n",
    "solver_data  = solver_data.replace(np.nan, \"Noval\")\n",
    "solver_data_copy = solver_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def split_collect(df_cols, delimiter=','):\n",
    "    \"\"\"\n",
    "        Split each value in a cell based on a delimiter \n",
    "        and return a list of unique options \n",
    "        \n",
    "    \"\"\"\n",
    "    opts = df_cols.apply(lambda x :  x.split(delimiter)   ).to_list()\n",
    "    flatten_opts = [x.strip() for y in opts for x in y ]\n",
    "    opts = pd.DataFrame(data=flatten_opts, columns=['options'])\n",
    "    opts = opts['options'].value_counts().index.to_list()\n",
    "    return opts\n",
    "\n",
    "\n",
    "def expand_col(df_col, delimiter=',',col_name='new_col'): \n",
    "    \"\"\"\n",
    "    Take in a pandas series whose elements are\n",
    "    a string. Split each cell of the series with\n",
    "    a delimiter which is used togenerate an N column dataframe. \n",
    "    N is the longest list amongst the cells of df_col after\n",
    "    they have been split\n",
    "    \n",
    "    \"\"\"\n",
    "#     df_col = df_col.apply(lambda x : x.str.split(delimiter)).to_list()\n",
    "    df_col = df_col.str.split(delimiter).to_list()\n",
    "    new_df = pd.DataFrame(data=df_col)\n",
    "    ncols = len(new_df.columns)\n",
    "    new_names = []\n",
    "    for x in range(1, ncols+1): \n",
    "        new_name =\"\".join((col_name,'_', str(x)))\n",
    "        new_df = new_df.rename(columns={x-1:new_name})\n",
    "    return new_df\n",
    "\n",
    "\n",
    "def match_single_to_multi(single_df, multi_df, single_match_on='None'): \n",
    "    \"\"\"\n",
    "    Generate a pivot table between a df which has a single of choices \n",
    "    and a df with multiple columns of choices\n",
    "    \n",
    "    \"\"\"\n",
    "    melted_df = pd.melt(multi_df,id_vars='Org')\n",
    "    melted_df = melted_df.drop(columns='variable')\n",
    "    melted_df = melted_df.apply(lambda x: x.str.strip() if x.dtype == \"object\" else x)\n",
    "    single_df = single_df.apply(lambda x: x.str.strip() if x.dtype == \"object\" else x)\n",
    "    matched_df = pd.merge(melted_df, single_df, how='outer', left_on='value', right_on=single_match_on)\n",
    "    matched_df = matched_df.replace(np.nan, 'Noval')\n",
    "    matched_df['value'] = matched_df['value'].apply(lambda x : 0 if x == None else 1)\n",
    "    pivot_table = pd.pivot_table(matched_df, index='Org_x', columns=['Org_y'], values='value', dropna=False,  aggfunc=np.sum)\n",
    "\n",
    "    return pivot_table\n",
    "\n",
    "\n",
    "def match_multi(df1, df2):\n",
    "    \"\"\"\n",
    "    Match a feature with multiple options to another option with multiple options\n",
    "    \"\"\"\n",
    "    \n",
    "    melted_df1 = pd.melt(df1,id_vars='Org').fillna('Noval')\n",
    "    melted_df2 = pd.melt(df2, id_vars='Org').fillna('Noval')\n",
    "    melted_df1 = melted_df1.drop(columns='variable')\n",
    "    melted_df2 = melted_df2.drop(columns='variable')\n",
    "    melted_df1 = melted_df1.apply(lambda x: x.str.strip() if x.dtype == \"object\" else x)\n",
    "    melted_df2 = melted_df2.apply(lambda x: x.str.strip() if x.dtype == \"object\" else x)\n",
    "    matched_df = pd.merge(melted_df1, melted_df2, how='outer', left_on='value', right_on='value')\n",
    "    matched_df = matched_df.replace(np.nan, 'Noval')\n",
    "    matched_df['value'] = matched_df['value'].apply(lambda x : 0 if  x == 'Noval' else 1)\n",
    "    pivot_table = pd.pivot_table(matched_df, index='Org_x', columns=['Org_y'], values='value',aggfunc=np.sum)\n",
    "    return pivot_table\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge column cleaning and matching\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "partner_challenge  = partner_data['Challenge Preference']\n",
    "partner_data['Challenge Preference'] = partner_data['Challenge Preference'].apply(lambda x: x.strip().replace(';',',') if ';' in x else x.strip() )\n",
    "partner_challenge_cols = expand_col(partner_data['Challenge Preference'], col_name ='Challenge')\n",
    "partner_challenge_opts = split_collect(partner_data['Challenge Preference'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "solver_challenge_opts = split_collect(solver_data['Challenge'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(solver_challenge_opts).issubset(set(partner_challenge_opts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above shows that all options in solvers are a subset of patners so no work required in correction! Next up is getting the matching sheet\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add challenge columns to partner data sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "partner_data_updated = partner_data.copy()\n",
    "partner_data_updated = partner_data_updated.drop(columns='Challenge Preference')\n",
    "partner_data_updated = pd.concat([partner_data_updated, partner_challenge_cols], axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Geo Interests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['North America',\n",
       " 'East Asia and Pacific',\n",
       " 'Sub-Saharan Africa',\n",
       " 'Europe and Central Asia',\n",
       " 'Latin America and the Caribbean',\n",
       " 'Middle East and North Africa',\n",
       " 'South Asia',\n",
       " 'Oceania',\n",
       " 'Noval']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "partner_data_updated['Geo Interest'] = partner_data_updated['Geo Interest'].apply(lambda x: x.strip().replace(';',',') if ';' in x else x.strip() )\n",
    "partner_geo_opts = split_collect(partner_data_updated['Geo Interest'])\n",
    "partner_geo_opts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Noval',\n",
       " 'North America',\n",
       " 'Sub-Saharan Africa',\n",
       " 'South Asia',\n",
       " 'Middle East and North Africa',\n",
       " 'Latin America and the Caribbean',\n",
       " 'Europe and Central Asia',\n",
       " 'East Asia and Pacific']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "solver_geo_opts = solver_data[['Geo 1', 'Geo 2', 'Geo 3']].apply(lambda x : \",\".join(x)   ,axis=1)\n",
    "solver_geo_opts = split_collect(solver_geo_opts)\n",
    "solver_geo_opts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(solver_geo_opts).issubset(set(partner_geo_opts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add geo columns to partner datasheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "partner_geo_cols = partner_data_updated['Geo Interest']\n",
    "\n",
    "partner_geo_cols = expand_col(partner_geo_cols, col_name='geo')\n",
    "\n",
    "# remove partner geo column and add individual geo columns\n",
    "partner_data_updated = pd.concat([partner_data_updated, partner_geo_cols], axis=1)\n",
    "partner_data_updated = partner_data_updated.drop(columns=['Geo Interest'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key needs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Noval',\n",
       " 'Business model (e.g. product-market fit, strategy & development)',\n",
       " 'Product / Service Distribution (e.g. expanding client base)',\n",
       " 'Monitoring & Evaluation (e.g. collecting/using data, measuring impact)',\n",
       " 'Human Capital (e.g. sourcing talent, board development, etc.)',\n",
       " 'Financial (e.g. improving accounting practices, pitching to investors)',\n",
       " 'Technology (e.g. software or hardware, web development/design, data analysis, etc.)',\n",
       " 'Public Relations (e.g. branding/marketing strategy, social and global media)',\n",
       " 'Other (explain below)',\n",
       " 'Legal or Regulatory Matters']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Partnership preferences non financal from partner data\n",
    "\n",
    "pref_name = 'Partnership Preference'\n",
    "prefs_columns = [x  for x in partner_data_updated.columns if pref_name in x]\n",
    "partner_prefs_opts = partner_data_updated[prefs_columns]\n",
    "partner_prefs_opts = split_collect(partner_prefs_opts.apply(lambda x : \";\".join(x)   ,axis=1), delimiter=';')\n",
    "partner_prefs_opts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Noval',\n",
       " 'Public Relations (e.g. branding/marketing strategy, social and global media)',\n",
       " 'Financial (e.g. improving accounting practices, pitching to investors)',\n",
       " 'Business model (e.g. product-market fit, strategy & development)',\n",
       " 'Human Capital (e.g. sourcing talent, board development, etc.)',\n",
       " 'Product / Service Distribution (e.g. expanding client base)',\n",
       " 'Technology (e.g. software or hardware, web development/design, data analysis, etc.)',\n",
       " 'Legal or Regulatory Matters',\n",
       " 'Other',\n",
       " 'Monitoring & Evaluation (e.g. collecting/using data, measuring impact)',\n",
       " 'Human Capital (i.e. sourcing talent, board development, etc.)']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "needs_name = 'Key Need'\n",
    "needs_columns = [x  for x in solver_data.columns if needs_name in x]\n",
    "solver_needs_opts = solver_data[needs_columns]\n",
    "solver_needs_opts = split_collect(solver_needs_opts.apply(lambda x : \";\".join(x)   ,axis=1), delimiter=';')\n",
    "solver_needs_opts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Human Capital (i.e. sourcing talent, board development, etc.)', 'Other'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if all the solver need options are in partner preferences\n",
    "set(solver_needs_opts).difference(set(partner_prefs_opts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Other (explain below)'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the opposite of the above\n",
    "set(partner_prefs_opts).difference(set(solver_needs_opts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correcting Human Captial in partner data\n",
    "wrong_str1 = 'Human Capital (e.g. sourcing talent, board development, etc.)'\n",
    "wrong_str2 = 'Other (explain below)'\n",
    "correct_str1 = 'Other'\n",
    "correct_str2 = 'Human Capital (i.e. sourcing talent, board development, etc.)'\n",
    "for pref in prefs_columns:\n",
    "    partner_data_updated[pref] = partner_data_updated[pref].apply(lambda x: x.replace(wrong_str1, correct_str1) if x == wrong_str1 else x )\n",
    "    partner_data_updated[pref] = partner_data_updated[pref].apply(lambda x: x.replace(wrong_str2, correct_str2) if x == wrong_str2 else x)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correcting Capital in solver data\n",
    "wrong_str1 = 'Human Capital (e.g. sourcing talent, board development, etc.)'\n",
    "correct_str2 = 'Human Capital (i.e. sourcing talent, board development, etc.)'\n",
    "solver_data_updated = solver_data.copy()\n",
    "for pref in needs_columns:\n",
    "    solver_data_updated[pref] = solver_data_updated[pref].apply(lambda x: x.replace(wrong_str1, correct_str1) if x == wrong_str1 else x )\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Noval',\n",
       " 'Other',\n",
       " 'Public Relations (e.g. branding/marketing strategy, social and global media)',\n",
       " 'Financial (e.g. improving accounting practices, pitching to investors)',\n",
       " 'Business model (e.g. product-market fit, strategy & development)',\n",
       " 'Product / Service Distribution (e.g. expanding client base)',\n",
       " 'Technology (e.g. software or hardware, web development/design, data analysis, etc.)',\n",
       " 'Legal or Regulatory Matters',\n",
       " 'Monitoring & Evaluation (e.g. collecting/using data, measuring impact)',\n",
       " 'Human Capital (i.e. sourcing talent, board development, etc.)']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Showing the partnership options after correcting for human capital\n",
    "needs_columns = [x  for x in solver_data_updated.columns if needs_name in x]\n",
    "solver_needs_opts = solver_data_updated[needs_columns]\n",
    "solver_needs_opts = split_collect(solver_needs_opts.apply(lambda x : \";\".join(x)   ,axis=1), delimiter=';')\n",
    "solver_needs_opts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage Match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "partner_data_updated['Solution Preference: Organization Stage'] = partner_data_updated['Solution Preference: Organization Stage'].apply(lambda x : x.replace(';',',' if ';' in x else x))\n",
    "partner_stage = partner_data_updated['Solution Preference: Organization Stage']\n",
    "partner_stage_opts = split_collect(partner_stage)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "solver_stage_opts = split_collect(solver_data_updated['Stage'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(solver_stage_opts).difference(set(partner_stage_opts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No difference! means all the options are the same! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add seprated stage columns to partner data sheet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "partner_stage_cols = expand_col(partner_stage, col_name='Stage')\n",
    "partner_data_updated = pd.concat([partner_data_updated, partner_stage_cols], axis=1)\n",
    "partner_data_updated = partner_data_updated.drop(columns=['Solution Preference: Organization Stage'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tech Match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Imaging and Sensor Technology', 'Virtual Reality / Augmented Reality'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "partner_tech_opts = split_collect(partner_data_updated['Technology Expertise'])\n",
    "tech_name = 'Tech'\n",
    "tech_cols = [x for x in solver_data_updated.columns if  tech_name in x]\n",
    "tech_cols.append('Org')\n",
    "solver_tech_cols = solver_data_updated[tech_cols]\n",
    "solver_tech_opts = split_collect(solver_tech_cols.apply(lambda x : \",\".join(x), axis=1))\n",
    "set(partner_tech_opts).difference(solver_tech_opts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'expand_col' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-0be6f28c5a3a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpartner_tech_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexpand_col\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpartner_data_updated\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Solution Preference: Technologies'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcol_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'tech'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mpartner_data_updated\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpartner_data_updated\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpartner_tech_cols\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mpartner_data_updated\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpartner_data_updated\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Solution Preference: Technologies'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'expand_col' is not defined"
     ]
    }
   ],
   "source": [
    "partner_tech_cols = expand_col(partner_data_updated['Technology Expertise'], col_name='tech')\n",
    "partner_data_updated = pd.concat([partner_data_updated, partner_tech_cols], axis=1)\n",
    "partner_data_updated = partner_data_updated.drop(columns=['Technology Expertise'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All matching sheets calculated here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Challenge Matching sheet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'Organization ID', 'Org', 'First Name', 'Last Name',\n",
       "       'Type', 'Funding Preference 1', 'Funding Preference 2',\n",
       "       'Funding Preference 3', 'Funding Preference 4',\n",
       "       'Partnership Preference: Non-Financial 1',\n",
       "       'Partnership Preference: Non-Financial 2',\n",
       "       'Partnership Preference: Non-Financial 3',\n",
       "       'Partnership Preference: Non-Financial 4',\n",
       "       'Partnership Preference: Non-Financial 5',\n",
       "       'Partnership Preference: Non-Financial 6',\n",
       "       'Partnership Preference: Non-Financial 7', 'Challenge_1', 'Challenge_2',\n",
       "       'Challenge_3', 'Challenge_4', 'Challenge_5', 'Challenge_6',\n",
       "       'Challenge_7', 'Challenge_8', 'Challenge_9', 'Challenge_10',\n",
       "       'Challenge_11', 'Challenge_12', 'Challenge_13', 'Challenge_14', 'geo_1',\n",
       "       'geo_2', 'geo_3', 'geo_4', 'geo_5', 'geo_6', 'geo_7', 'geo_8',\n",
       "       'Stage_1', 'Stage_2', 'Stage_3', 'Stage_4', 'Stage_5', 'tech_1',\n",
       "       'tech_2', 'tech_3', 'tech_4', 'tech_5', 'tech_6', 'tech_7', 'tech_8',\n",
       "       'tech_9'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "partner_data_updated = partner_data_updated.replace('None', 'Noval' ,regex=True)\n",
    "solver_data_updated = solver_data_updated.replace('None', 'Noval', regex=True)\n",
    "partner_data_updated = partner_data_updated.replace(np.nan, \"Noval\")\n",
    "solver_data_updated  = solver_data_updated.replace(np.nan, \"Noval\")\n",
    "partner_data_updated.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "chname = 'Challenge'\n",
    "challenge_cols = [x for x in partner_data_updated.columns if chname in x ]\n",
    "partner_challenge_cols = partner_data_updated[challenge_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pawan/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(78, 43)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "solver_challenge_cols = solver_data_updated[['Org', 'Challenge']]\n",
    "partner_challenge_cols['Org'] = partner_data_updated['Org']\n",
    "challenge_match = match_single_to_multi(solver_challenge_cols, partner_challenge_cols, single_match_on='Challenge')\n",
    "\n",
    "if 'Noval' in challenge_match.columns: \n",
    "    challenge_match = challenge_match.drop(columns=['Noval'])\n",
    "challenge_match.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening up single to multi function \n",
    "\n",
    "# single_df = solver_challenge_cols\n",
    "# multi_df = partner_challenge_cols\n",
    "# single_match_on = 'Challenge'\n",
    "\n",
    "# melted_df = pd.melt(multi_df,id_vars='Org')\n",
    "# melted_df = melted_df.drop(columns='variable')\n",
    "# melted_df = melted_df.apply(lambda x: x.str.strip() if x.dtype == \"object\" else x)\n",
    "# single_df = single_df.apply(lambda x: x.str.strip() if x.dtype == \"object\" else x)\n",
    "# matched_df = pd.merge(melted_df, single_df, how='outer', left_on='value', right_on=single_match_on)\n",
    "# matched_df = matched_df.replace(np.nan, 'Noval')\n",
    "# matched_df['value'] = matched_df['value'].apply(lambda x : 0 if x == None else 1)\n",
    "# pivot_table = pd.pivot_table(matched_df, index='Org_x', columns=['Org_y'], values='value', dropna=False,  aggfunc=np.sum)\n",
    "# pivot_table.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trouble shooting no match "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unshared_challenges_partners = set(partner_challenge_cols['Org'].to_list()).difference(set(pivot_table.index.to_list()))\n",
    "# challenges_missing = set(partner_challenge_opts).difference(set(solver_challenge_opts))\n",
    "# missing_indx = partner_challenge_cols[partner_challenge_cols.isin(challenges_missing)].any(1).to_numpy().nonzero()\n",
    "# possible_missing = partner_challenge_cols['Org'].loc[missing_indx].to_list()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This basically means that there are only 35 rows have matches, otherwise no matches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Geo Matching sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(78, 43)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "geo_cols = [x for x in partner_data_updated.columns if 'geo' in x]\n",
    "geo_cols.append('Org')\n",
    "partner_geo_cols = partner_data_updated[geo_cols]\n",
    "\n",
    "solver_geo_cols = solver_data_updated[['Org', 'Geo 1', 'Geo 2', 'Geo 3']]\n",
    "geo_match = match_multi(partner_geo_cols,solver_geo_cols)\n",
    "if 'Noval' in geo_match.columns: \n",
    "    geo_match = geo_match.drop(columns=['Noval'])\n",
    "geo_match.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Needs Matching sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(78, 43)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "needs_name ='Key Need'\n",
    "pref_name = 'Partnership Preference'\n",
    "prefs_columns = [x  for x in partner_data_updated.columns if pref_name in x]\n",
    "needs_columns = [x  for x in solver_data_updated.columns if needs_name in x]\n",
    "prefs_columns.append('Org')\n",
    "needs_columns.append('Org')\n",
    "partner_prefs_cols = partner_data_updated[prefs_columns]\n",
    "solver_needs_cols = solver_data_updated[needs_columns]\n",
    "needs_match = match_multi(partner_prefs_cols, solver_needs_cols)\n",
    "if 'Noval' in needs_match.columns: \n",
    "    needs_match = needs_match.drop(columns=['Noval'])\n",
    "needs_match.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage Matching sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(78, 43)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stage_name = 'Stage'\n",
    "stage_columns = [x  for x in partner_data_updated.columns if stage_name in x]\n",
    "stage_columns.append('Org')\n",
    "partner_stage_cols = partner_data_updated[stage_columns]\n",
    "solver_stage_cols = solver_data_updated[['Stage', 'Org']]\n",
    "stage_match = match_single_to_multi(solver_stage_cols, partner_stage_cols, single_match_on='Stage')\n",
    "\n",
    "if 'Noval' in stage_match.columns: \n",
    "    stage_match = stage_match.drop(columns=['Noval'])\n",
    "stage_match.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(stage_match.columns.to_list()).difference(set(needs_match.columns.to_list()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tech Matching Sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "tech_name = 'tech'\n",
    "tech_cols = [x for x in partner_data_updated.columns if  tech_name in x]\n",
    "tech_cols.append('Org')\n",
    "partner_tech_cols = partner_data_updated[tech_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pawan/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(78, 43)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "partner_tech_cols['Org'] = partner_data_updated['Org']\n",
    "tech_match = match_multi(partner_tech_cols, solver_tech_cols)\n",
    "if 'Noval' in tech_match.columns:\n",
    "    tech_match = tech_match.drop(columns=['Noval'])\n",
    "if 'Noval' in tech_match.index:\n",
    "    tech_match = tech_match.drop(index='Noval', axis=0) \n",
    "tech_match.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summing all sheets \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tech_matched = tech_matched.fillna(0)\n",
    "needs_match = needs_match.fillna(0)\n",
    "geo_match = geo_match.fillna(0)\n",
    "stage_match= stage_match.fillna(0)\n",
    "challenge_match = challenge_match.fillna(0)\n",
    "\n",
    "partner_solver_weights = pd.read_excel('input_data/2020_input_data.xlsx', sheet_name= 'Partner Solver Weights')\n",
    "geo_weights_pivot = pd.pivot(partner_solver_weights[['Org_y', 'Org_x', 'geo_weights']], columns='Org_x', index='Org_y' )\n",
    "needs_weights_pivot = pd.pivot(partner_solver_weights[['Org_y', 'Org_x', 'needs_weights']], columns='Org_x', index='Org_y' )\n",
    "challenge_weights_pivot = pd.pivot(partner_solver_weights[['Org_y', 'Org_x', 'challenge_weights']], columns='Org_x', index='Org_y' )\n",
    "stage_weights_pivot = pd.pivot(partner_solver_weights[['Org_y', 'Org_x', 'stage_weights']], columns='Org_x', index='Org_y' )\n",
    "\n",
    "challenge_term = 10*pd.DataFrame(challenge_weights_pivot.values*challenge_match.astype(float).values, columns=challenge_weights_pivot.columns, index=challenge_weights_pivot.index)['challenge_weights']\n",
    "stage_term = pd.DataFrame(stage_weights_pivot.values*stage_match.astype(float).values, columns=stage_weights_pivot.columns, index=stage_weights_pivot.index)\n",
    "geo_term = pd.DataFrame(geo_weights_pivot.values*geo_match.astype(float).values, columns=geo_weights_pivot.columns, index=geo_weights_pivot.index)['geo_weights']\n",
    "geo_stage_term = 100*pd.DataFrame(geo_term.values*stage_term.values, columns=stage_term.columns, index=stage_term.index)['stage_weights']\n",
    "needs_term =  pd.DataFrame(needs_weights_pivot.values*needs_match.astype(float).values, columns=needs_weights_pivot.columns, index=needs_weights_pivot.index)['needs_weights']\n",
    "\n",
    "total_score = challenge_term  + geo_stage_term + needs_term\n",
    "# partner_solver_weights['Org_x'].value_counts().index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "partner_data_updated = partner_data_updated.replace('None', 'Noval' ,regex=True)\n",
    "solver_data_updated = solver_data_updated.replace('None', 'Noval', regex=True)\n",
    "partner_data_updated = partner_data_updated.replace(np.nan, \"Noval\")\n",
    "solver_data_updated  = solver_data_updated.replace(np.nan, \"Noval\")\n",
    "\n",
    "file_name = '2020_data.xlsx'\n",
    "with pd.ExcelWriter(file_name) as writer: \n",
    "    partner_data_updated.to_excel(writer, sheet_name='Partner Data', index=False)\n",
    "    solver_data_updated.to_excel(writer, sheet_name='Solver Team Data', index= False)\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check sort values for the output graphs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "uploaded_df_total_score = pd.read_excel(\"input_data/total_score_from_upload.xlsx\", sheet_name=\"Sheet1\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Org_y</th>\n",
       "      <th>EA Ecoversity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Comcast NBCUniversal</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>Someone Else's Child Foundation</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>BMW Foundation Herbert Quandt</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Llamasoft</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Merian Ventures</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Morgridge Family Foundation</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Global Fund to fight Aids, Tuberculosis and Ma...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>KSF Impact</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Leap Ventures</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>Queen Rania Foundation for Education and Devel...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>78 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Org_y  EA Ecoversity\n",
       "16                               Comcast NBCUniversal           13.0\n",
       "58                    Someone Else's Child Foundation           12.0\n",
       "6                       BMW Foundation Herbert Quandt           11.0\n",
       "40                                          Llamasoft            6.0\n",
       "44                                    Merian Ventures            6.0\n",
       "..                                                ...            ...\n",
       "46                        Morgridge Family Foundation            1.0\n",
       "29  Global Fund to fight Aids, Tuberculosis and Ma...            0.0\n",
       "35                                         KSF Impact            0.0\n",
       "38                                      Leap Ventures            0.0\n",
       "54  Queen Rania Foundation for Education and Devel...            0.0\n",
       "\n",
       "[78 rows x 2 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "value = 'EA Ecoversity'\n",
    "solver_scores = uploaded_df_total_score[['Org_y', value]]\n",
    "uploaded_df_total_score.sort_values(value,  ascending=False)[:5]\n",
    "solver_scores.sort_values(by=[ value], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Org_y</th>\n",
       "      <th>AHSA Platform</th>\n",
       "      <th>Amplify Her Voice</th>\n",
       "      <th>Asia Initiatives Learning Cascades</th>\n",
       "      <th>Bambara Milk</th>\n",
       "      <th>Beewise</th>\n",
       "      <th>Bioforge Neonatal Incubator</th>\n",
       "      <th>Biometricsfor vaccine delivery</th>\n",
       "      <th>D2</th>\n",
       "      <th>Democratizing Ultrasound Africa</th>\n",
       "      <th>...</th>\n",
       "      <th>Someone Somewhere</th>\n",
       "      <th>Symbrosia</th>\n",
       "      <th>TamoJunto.org.br</th>\n",
       "      <th>Thaki</th>\n",
       "      <th>The Last Mile</th>\n",
       "      <th>Ubenwa</th>\n",
       "      <th>Universally Friendly Obturator</th>\n",
       "      <th>Whole Surplus</th>\n",
       "      <th>Yiya AirScience</th>\n",
       "      <th>eggXYt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Comcast NBCUniversal</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>Someone Else's Child Foundation</td>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>BMW Foundation Herbert Quandt</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Llamasoft</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>17</td>\n",
       "      <td>12</td>\n",
       "      <td>15</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Merian Ventures</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Org_y  AHSA Platform  Amplify Her Voice  \\\n",
       "16             Comcast NBCUniversal              4                  3   \n",
       "58  Someone Else's Child Foundation              6                 14   \n",
       "6     BMW Foundation Herbert Quandt              2                  2   \n",
       "40                        Llamasoft              4                 12   \n",
       "44                  Merian Ventures              6                  2   \n",
       "\n",
       "    Asia Initiatives Learning Cascades  Bambara Milk  Beewise  \\\n",
       "16                                   6             1        2   \n",
       "58                                  16             2        2   \n",
       "6                                    4             1        2   \n",
       "40                                  17            12       15   \n",
       "44                                   6            11       16   \n",
       "\n",
       "    Bioforge Neonatal Incubator  Biometricsfor vaccine delivery  D2  \\\n",
       "16                            2                               3  12   \n",
       "58                            2                               4  12   \n",
       "6                             0                               3  10   \n",
       "40                           11                               2   3   \n",
       "44                            1                               2  12   \n",
       "\n",
       "    Democratizing Ultrasound Africa  ...  Someone Somewhere  Symbrosia  \\\n",
       "16                                2  ...                 13          4   \n",
       "58                                3  ...                 14          4   \n",
       "6                                 3  ...                 14          1   \n",
       "40                               13  ...                  5         12   \n",
       "44                                2  ...                 13         13   \n",
       "\n",
       "    TamoJunto.org.br  Thaki  The Last Mile  Ubenwa  \\\n",
       "16                13      5             14       2   \n",
       "58                14     14             13       2   \n",
       "6                 13      4             13       1   \n",
       "40                 3     16              4      13   \n",
       "44                12      4             14       3   \n",
       "\n",
       "    Universally Friendly Obturator  Whole Surplus  Yiya AirScience  eggXYt  \n",
       "16                               6              2                5       2  \n",
       "58                               6              2               16       3  \n",
       "6                                2              2                2       1  \n",
       "40                              13             14               14      12  \n",
       "44                               3             16                5      11  \n",
       "\n",
       "[5 rows x 44 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uploaded_df_total_score.sort_values(value,  ascending=False)[:5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49    3.0\n",
       "Name: EA Ecoversity, dtype: float64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "solver_scores[solver_scores['Org_y'] == 'Nuvo']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16    12\n",
       "Name: D2, dtype: int64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uploaded_df_total_score.sort_values(value,  ascending=False)[:1]['D2']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Solvers</th>\n",
       "      <th>matches</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AHSA Platform</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Biometricsfor vaccine delivery</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jute-based biodegradable PPE</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MapSights</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mosquito-borne disease prevention</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>PENSA *660#</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>PODD</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>EA Ecoversity</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Food from Fire</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Indigenous DC</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Indigikitchen</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>International Wakashan AI-Consortium</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Protect Medicinal Plants</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ShockTalk</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Sicangu Online Marketplace</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>D2</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Humans inthe Loop</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Nucleus</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>SOLshare</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Someone Somewhere</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>TamoJunto.org.br</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>The Last Mile</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Amplify Her Voice</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Asia Initiatives Learning Cascades</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Empower 1.5M Girls to go to School</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Girls-4-Girls</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Sisters of Code</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Thaki</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Yiya AirScience</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Bioforge Neonatal Incubator</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Democratizing Ultrasound Africa</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Maisha</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Maziwa Breast Pump</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Salamat</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Ubenwa</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Universally Friendly Obturator</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Bambara Milk</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Beewise</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>eggXYt</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>InsectiPro</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>SmartFish Mexico</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Symbrosia</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Whole Surplus</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Solvers matches\n",
       "0                          AHSA Platform    None\n",
       "1         Biometricsfor vaccine delivery    None\n",
       "2           Jute-based biodegradable PPE    None\n",
       "3                              MapSights    None\n",
       "4      Mosquito-borne disease prevention    None\n",
       "5                            PENSA *660#    None\n",
       "6                                   PODD    None\n",
       "7                          EA Ecoversity    None\n",
       "8                         Food from Fire    None\n",
       "9                          Indigenous DC    None\n",
       "10                         Indigikitchen    None\n",
       "11  International Wakashan AI-Consortium    None\n",
       "12              Protect Medicinal Plants    None\n",
       "13                             ShockTalk    None\n",
       "14            Sicangu Online Marketplace    None\n",
       "15                                    D2    None\n",
       "16                     Humans inthe Loop    None\n",
       "17                               Nucleus    None\n",
       "18                              SOLshare    None\n",
       "19                     Someone Somewhere    None\n",
       "20                      TamoJunto.org.br    None\n",
       "21                         The Last Mile    None\n",
       "22                     Amplify Her Voice    None\n",
       "23    Asia Initiatives Learning Cascades    None\n",
       "24    Empower 1.5M Girls to go to School    None\n",
       "25                         Girls-4-Girls    None\n",
       "26                       Sisters of Code    None\n",
       "27                                 Thaki    None\n",
       "28                       Yiya AirScience    None\n",
       "29           Bioforge Neonatal Incubator    None\n",
       "30       Democratizing Ultrasound Africa    None\n",
       "31                                Maisha    None\n",
       "32                    Maziwa Breast Pump    None\n",
       "33                               Salamat    None\n",
       "34                                Ubenwa    None\n",
       "35        Universally Friendly Obturator    None\n",
       "36                          Bambara Milk    None\n",
       "37                               Beewise    None\n",
       "38                                eggXYt    None\n",
       "39                            InsectiPro    None\n",
       "40                      SmartFish Mexico    None\n",
       "41                             Symbrosia    None\n",
       "42                         Whole Surplus    None"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "solver_options = solver_data_updated['Org']\n",
    "solver_options = solver_options.to_frame(name='Solvers')\n",
    "matches = ['None' for x in range(0, solver_options.shape[0])]\n",
    "solver_options['matches'] = matches\n",
    "solver_options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'None'"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_val = \"D2\"\n",
    "row_indx = solver_options[solver_options['Solvers'] == 'Thaki'].index[0]\n",
    "solver_options.iloc[row_indx, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def update_colval(df,add_term, row_val, col, col2): \n",
    "    col_indx = df[df[col] == row_val].index.values[0]\n",
    "    cell_val = df.at[col_indx, col2]\n",
    "    cell_val = cell_val.split(',')\n",
    "    if add_term in cell_val: \n",
    "        return  1 \n",
    "    else: \n",
    "        cell_val.append(add_term)\n",
    "        count_value = len(cell_val)-1 \n",
    "        cell_val = \",\".join(cell_val)\n",
    "        df.at[col_indx, col2] = cell_val\n",
    "        df.at[col_indx, 'Count'] =  count_value \n",
    "        return df, count_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(                                 Solvers            matches  Count\n",
       " 0                          AHSA Platform               None    NaN\n",
       " 1         Biometricsfor vaccine delivery               None    NaN\n",
       " 2           Jute-based biodegradable PPE               None    NaN\n",
       " 3                              MapSights               None    NaN\n",
       " 4      Mosquito-borne disease prevention               None    NaN\n",
       " 5                            PENSA *660#               None    NaN\n",
       " 6                                   PODD               None    NaN\n",
       " 7                          EA Ecoversity               None    NaN\n",
       " 8                         Food from Fire               None    NaN\n",
       " 9                          Indigenous DC               None    NaN\n",
       " 10                         Indigikitchen               None    NaN\n",
       " 11  International Wakashan AI-Consortium               None    NaN\n",
       " 12              Protect Medicinal Plants               None    NaN\n",
       " 13                             ShockTalk               None    NaN\n",
       " 14            Sicangu Online Marketplace               None    NaN\n",
       " 15                                    D2  None,Thaki?,Thaki    2.0\n",
       " 16                     Humans inthe Loop               None    NaN\n",
       " 17                               Nucleus               None    NaN\n",
       " 18                              SOLshare               None    NaN\n",
       " 19                     Someone Somewhere               None    NaN\n",
       " 20                      TamoJunto.org.br               None    NaN\n",
       " 21                         The Last Mile               None    NaN\n",
       " 22                     Amplify Her Voice               None    NaN\n",
       " 23    Asia Initiatives Learning Cascades               None    NaN\n",
       " 24    Empower 1.5M Girls to go to School               None    NaN\n",
       " 25                         Girls-4-Girls               None    NaN\n",
       " 26                       Sisters of Code               None    NaN\n",
       " 27                                 Thaki            None,D2    1.0\n",
       " 28                       Yiya AirScience               None    NaN\n",
       " 29           Bioforge Neonatal Incubator               None    NaN\n",
       " 30       Democratizing Ultrasound Africa               None    NaN\n",
       " 31                                Maisha               None    NaN\n",
       " 32                    Maziwa Breast Pump               None    NaN\n",
       " 33                               Salamat               None    NaN\n",
       " 34                                Ubenwa               None    NaN\n",
       " 35        Universally Friendly Obturator               None    NaN\n",
       " 36                          Bambara Milk               None    NaN\n",
       " 37                               Beewise               None    NaN\n",
       " 38                                eggXYt               None    NaN\n",
       " 39                            InsectiPro               None    NaN\n",
       " 40                      SmartFish Mexico               None    NaN\n",
       " 41                             Symbrosia               None    NaN\n",
       " 42                         Whole Surplus               None    NaN,\n",
       " 1)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "update_colval(solver_options,add_val, \"Thaki\", \"Solvers\", \"matches\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['None',\n",
       " 'The Kamath Family Foundation',\n",
       " 'Usizo Advisory Solutions',\n",
       " 'Kevin Przybocki']"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "solver_opts = pd.read_excel('input_data/solver_options.xlsx')\n",
    "solver_opts[solver_opts['Solvers'] == 'AHSA Platform']['matches'][0].split(',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
